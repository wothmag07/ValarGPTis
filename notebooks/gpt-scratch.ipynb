{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import csv\\n\\n# Input CSV file path\\ncsv_file = r\"D:\\\\Workspace\\nanoGPT\\\\Game_of_Thrones_Script.csv\"  # Change this to your actual file path\\n# Output TXT file path\\ntxt_file = r\"D:\\\\Workspace\\nanoGPT\\\\got_script.txt\"\\n\\nwith open(csv_file, mode=\"r\", encoding=\"utf-8\") as infile, open(txt_file, mode=\"w\", encoding=\"utf-8\") as outfile:\\n    reader = csv.reader(infile)\\n    next(reader)  # Skip the header\\n\\n    for row in reader:\\n        name = row[4].strip()  # Name column\\n        sentence = row[5].strip()  # Sentence column\\n        outfile.write(f\"{name}:\\n{sentence}\\n\\n\")\\n\\nprint(f\"Conversion complete! File saved as {txt_file}\")'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import csv\n",
    "\n",
    "# Input CSV file path\n",
    "csv_file = r\"D:\\Workspace\\nanoGPT\\Game_of_Thrones_Script.csv\"  # Change this to your actual file path\n",
    "# Output TXT file path\n",
    "txt_file = r\"D:\\Workspace\\nanoGPT\\got_script.txt\"\n",
    "\n",
    "with open(csv_file, mode=\"r\", encoding=\"utf-8\") as infile, open(txt_file, mode=\"w\", encoding=\"utf-8\") as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    next(reader)  # Skip the header\n",
    "\n",
    "    for row in reader:\n",
    "        name = row[4].strip()  # Name column\n",
    "        sentence = row[5].strip()  # Sentence column\n",
    "        outfile.write(f\"{name}:\\n{sentence}\\n\\n\")\n",
    "\n",
    "print(f\"Conversion complete! File saved as {txt_file}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = r\"D:\\Workspace\\nanoGPT\\got_script.txt\"\n",
    "with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of words in the script : 1827291\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of words in the script : {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#'*,-./0123456789:;>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz{éêāēū–—‘“”…\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab = ''.join(chars)\n",
    "vocabSize = len(chars)\n",
    "print(vocab)\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waymar royce:\n",
      "What do you expect? They're savages. One lot steals a goat from another lot and before you know it, they're ripping each other to pieces.\n",
      "will:\n",
      "I've never seen wildlings do a thing like this. I've never seen a thing like this, not ever in my life.\n",
      "waymar royce:\n",
      "How close did you get?\n",
      "will:\n",
      "Close as any man would.\n",
      "gared:\n",
      "We should head back to the wall.\n",
      "royce:\n",
      "Do the dead frighten you?\n",
      "gared:\n",
      "Our orders were to track the wildlings. We tracked them. They won't trouble us no more.\n",
      "royce:\n",
      "You don't think he'll ask us how they died? Get back on your horse.\n",
      "will:\n",
      "Whatever did it to them could do it to us. They even killed the children.\n",
      "royce:\n",
      "It's a good thing we're not children. You want to run away south, run away. Of course, they will behead you as a deserter … If I don't catch you first. Get back on your horse. I won't say it again.\n",
      "royce:\n",
      "Your dead men seem to have moved camp.\n",
      "will:\n",
      "They were here.\n",
      "gared:\n",
      "See where they went.\n",
      "royce:\n",
      "What is it?\n",
      "gared:\n",
      "It's …\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the text by double newlines and print each segment separately\n",
    "lines = text[:1000].split('\\n\\n')\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [32, 61, 1, 72, 60, 57, 70, 57, 2, 2]\n",
      "Decoded: Hi there!!\n"
     ]
    }
   ],
   "source": [
    "#Token mapping\n",
    "\n",
    "# Define the allowed character set\n",
    "unk_token = \"<unk>\"\n",
    "\n",
    "# Create mappings\n",
    "token2id = {s: i for i, s in enumerate(chars)}\n",
    "token2id[unk_token] = len(chars)  # Assign the next available index to <unk>\n",
    "\n",
    "id2token = {i: s for s, i in token2id.items()}\n",
    "id2token[len(chars)] = unk_token  # Reverse mapping for <unk>\n",
    "\n",
    "# Encoding function with unknown token handling\n",
    "def encode(token):\n",
    "    return [token2id.get(char, token2id[unk_token]) for char in token]\n",
    "\n",
    "# Decoding function\n",
    "def decode(ids):\n",
    "    return ''.join(id2token.get(i, unk_token) for i in ids)\n",
    "\n",
    "# Test case\n",
    "test_string = \"Hi there!!\"\n",
    "encoded = encode(test_string)\n",
    "decoded = decode(encoded)\n",
    "\n",
    "print(\"Encoded:\", encoded)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1827291])\n",
      "tensor([75, 53, 77, 65, 53, 70,  1, 70, 67, 77, 55, 57, 21,  0, 47, 60, 53, 72,\n",
      "         1, 56, 67,  1, 77, 67, 73,  1, 57, 76, 68, 57, 55, 72, 24,  1, 44, 60,\n",
      "        57, 77,  5, 70, 57,  1, 71, 53, 74, 53, 59, 57, 71,  9,  1, 39, 66, 57,\n",
      "         1, 64, 67, 72,  1, 71, 72, 57, 53, 64, 71,  1, 53,  1, 59, 67, 53, 72,\n",
      "         1, 58, 70, 67, 65,  1, 53, 66, 67, 72, 60, 57, 70,  1, 64, 67, 72,  1,\n",
      "        53, 66, 56,  1, 54, 57, 58, 67, 70, 57,  1, 77, 67, 73,  1, 63, 66, 67,\n",
      "        75,  1, 61, 72,  7,  1, 72, 60, 57, 77,  5, 70, 57,  1, 70, 61, 68, 68,\n",
      "        61, 66, 59,  1, 57, 53, 55, 60,  1, 67, 72, 60, 57, 70,  1, 72, 67,  1,\n",
      "        68, 61, 57, 55, 57, 71,  9,  0,  0, 75, 61, 64, 64, 21,  0, 33,  5, 74,\n",
      "        57,  1, 66, 57, 74, 57, 70,  1, 71, 57, 57, 66,  1, 75, 61, 64, 56, 64,\n",
      "        61, 66, 59, 71,  1, 56, 67,  1, 53,  1, 72, 60, 61, 66, 59,  1, 64, 61,\n",
      "        63, 57,  1, 72, 60, 61, 71,  9,  1, 33,  5, 74, 57,  1, 66, 57, 74, 57,\n",
      "        70,  1, 71, 57, 57, 66,  1, 53,  1, 72, 60, 61, 66, 59,  1, 64, 61, 63,\n",
      "        57,  1, 72, 60, 61, 71,  7,  1, 66, 67, 72,  1, 57, 74, 57, 70,  1, 61,\n",
      "        66,  1, 65, 77,  1, 64, 61, 58, 57,  9,  0,  0, 75, 53, 77, 65, 53, 70,\n",
      "         1, 70, 67, 77, 55, 57, 21,  0, 32, 67, 75,  1, 55, 64, 67, 71, 57,  1,\n",
      "        56, 61, 56,  1, 77, 67, 73,  1, 59, 57, 72, 24,  0,  0, 75, 61, 64, 64,\n",
      "        21,  0, 27, 64, 67, 71, 57,  1, 53, 71,  1, 53, 66, 77,  1, 65, 53, 66,\n",
      "         1, 75, 67, 73, 64, 56,  9,  0,  0, 59, 53, 70, 57, 56, 21,  0, 47, 57,\n",
      "         1, 71, 60, 67, 73, 64, 56,  1, 60, 57, 53, 56,  1, 54, 53, 55, 63,  1,\n",
      "        72, 67,  1, 72, 60, 57,  1, 75, 53, 64, 64,  9,  0,  0, 70, 67, 77, 55,\n",
      "        57, 21,  0, 28, 67,  1, 72, 60, 57,  1, 56, 57, 53, 56,  1, 58, 70, 61,\n",
      "        59, 60, 72, 57, 66,  1, 77, 67, 73, 24,  0,  0, 59, 53, 70, 57, 56, 21,\n",
      "         0, 39, 73, 70,  1, 67, 70, 56, 57, 70, 71,  1, 75, 57, 70, 57,  1, 72,\n",
      "        67,  1, 72, 70, 53, 55, 63,  1, 72, 60, 57,  1, 75, 61, 64, 56, 64, 61,\n",
      "        66, 59, 71,  9,  1, 47, 57,  1, 72, 70, 53, 55, 63, 57, 56,  1, 72, 60,\n",
      "        57, 65,  9,  1, 44, 60, 57, 77,  1, 75, 67, 66,  5, 72,  1, 72, 70, 67,\n",
      "        73, 54, 64, 57,  1, 73, 71,  1, 66, 67,  1, 65, 67, 70, 57,  9,  0,  0,\n",
      "        70, 67, 77, 55, 57, 21,  0, 49, 67, 73,  1, 56, 67, 66,  5, 72,  1, 72,\n",
      "        60, 61, 66, 63,  1, 60, 57,  5, 64, 64,  1, 53, 71, 63,  1, 73, 71,  1,\n",
      "        60, 67, 75,  1, 72, 60, 57, 77,  1, 56, 61, 57, 56, 24,  1, 31, 57, 72,\n",
      "         1, 54, 53, 55, 63,  1, 67, 66,  1, 77, 67, 73, 70,  1, 60, 67, 70, 71,\n",
      "        57,  9,  0,  0, 75, 61, 64, 64, 21,  0, 47, 60, 53, 72, 57, 74, 57, 70,\n",
      "         1, 56, 61, 56,  1, 61, 72,  1, 72, 67,  1, 72, 60, 57, 65,  1, 55, 67,\n",
      "        73, 64, 56,  1, 56, 67,  1, 61, 72,  1, 72, 67,  1, 73, 71,  9,  1, 44,\n",
      "        60, 57, 77,  1, 57, 74, 57, 66,  1, 63, 61, 64, 64, 57, 56,  1, 72, 60,\n",
      "        57,  1, 55, 60, 61, 64, 56, 70, 57, 66,  9,  0,  0, 70, 67, 77, 55, 57,\n",
      "        21,  0, 33, 72,  5, 71,  1, 53,  1, 59, 67, 67, 56,  1, 72, 60, 61, 66,\n",
      "        59,  1, 75, 57,  5, 70, 57,  1, 66, 67, 72,  1, 55, 60, 61, 64, 56, 70,\n",
      "        57, 66,  9,  1, 49, 67, 73,  1, 75, 53, 66, 72,  1, 72, 67,  1, 70, 73,\n",
      "        66,  1, 53, 75, 53, 77,  1, 71, 67, 73, 72, 60,  7,  1, 70, 73, 66,  1,\n",
      "        53, 75, 53, 77,  9,  1, 39, 58,  1, 55, 67, 73, 70, 71, 57,  7,  1, 72,\n",
      "        60, 57, 77,  1, 75, 61, 64, 64,  1, 54, 57, 60, 57, 53, 56,  1, 77, 67,\n",
      "        73,  1, 53, 71,  1, 53,  1, 56, 57, 71, 57, 70, 72, 57, 70,  1, 90,  1,\n",
      "        33, 58,  1, 33,  1, 56, 67, 66,  5, 72,  1, 55, 53, 72, 55, 60,  1, 77,\n",
      "        67, 73,  1, 58, 61, 70, 71, 72,  9,  1, 31, 57, 72,  1, 54, 53, 55, 63,\n",
      "         1, 67, 66,  1, 77, 67, 73, 70,  1, 60, 67, 70, 71, 57,  9,  1, 33,  1,\n",
      "        75, 67, 66,  5, 72,  1, 71, 53, 77,  1, 61, 72,  1, 53, 59, 53, 61, 66,\n",
      "         9,  0,  0, 70, 67, 77, 55, 57, 21,  0, 49, 67, 73, 70,  1, 56, 57, 53,\n",
      "        56,  1, 65, 57, 66,  1, 71, 57, 57, 65,  1, 72, 67,  1, 60, 53, 74, 57,\n",
      "         1, 65, 67, 74, 57, 56,  1, 55, 53, 65, 68,  9,  0,  0, 75, 61, 64, 64,\n",
      "        21,  0, 44, 60, 57, 77,  1, 75, 57, 70, 57,  1, 60, 57, 70, 57,  9,  0,\n",
      "         0, 59, 53, 70, 57, 56, 21,  0, 43, 57, 57,  1, 75, 60, 57, 70, 57,  1,\n",
      "        72, 60, 57, 77,  1, 75, 57, 66, 72,  9,  0,  0, 70, 67, 77, 55, 57, 21,\n",
      "         0, 47, 60, 53, 72,  1, 61, 71,  1, 61, 72, 24,  0,  0, 59, 53, 70, 57,\n",
      "        56, 21,  0, 33, 72,  5, 71,  1, 90,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "text_tensor = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(text_tensor.shape)\n",
    "print(text_tensor[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitSize = int(0.9 * len(text))\n",
    "trainTensor = text_tensor[:splitSize]\n",
    "validTensor = text[splitSize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([75, 53, 77, 65, 53, 70,  1, 70, 67])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blockSize = 8\n",
    "trainTensor[:blockSize+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs : tensor([75]) -> Target : 53\n",
      "Inputs : tensor([75, 53]) -> Target : 77\n",
      "Inputs : tensor([75, 53, 77]) -> Target : 65\n",
      "Inputs : tensor([75, 53, 77, 65]) -> Target : 53\n",
      "Inputs : tensor([75, 53, 77, 65, 53]) -> Target : 70\n",
      "Inputs : tensor([75, 53, 77, 65, 53, 70]) -> Target : 1\n",
      "Inputs : tensor([75, 53, 77, 65, 53, 70,  1]) -> Target : 70\n",
      "Inputs : tensor([75, 53, 77, 65, 53, 70,  1, 70]) -> Target : 67\n"
     ]
    }
   ],
   "source": [
    "x = trainTensor[:blockSize]\n",
    "y = trainTensor[1:blockSize+1]\n",
    "\n",
    "for block in range(blockSize):\n",
    "    context = x[:block+1]\n",
    "    target = y[block]\n",
    "    print(f\"Inputs : {context} -> Target : {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs :\n",
      "tensor([[54, 53, 70, 53, 72, 60, 57, 67],\n",
      "        [60, 57, 77,  5, 64, 64,  1, 63],\n",
      "        [72, 60,  1, 72, 60, 57,  1, 75],\n",
      "        [63, 71,  1, 57, 74, 57, 70, 77],\n",
      "        [67, 70, 70, 77,  1, 33,  1, 75],\n",
      "        [53, 71,  1, 53,  1, 75, 67, 65],\n",
      "        [75, 61, 64, 64,  1, 54, 57,  1],\n",
      "        [56,  9,  1, 40, 67, 56,  7,  1]])\n",
      "targets:\n",
      "tensor([[53, 70, 53, 72, 60, 57, 67, 66],\n",
      "        [57, 77,  5, 64, 64,  1, 63, 61],\n",
      "        [60,  1, 72, 60, 57,  1, 75, 60],\n",
      "        [71,  1, 57, 74, 57, 70, 77,  1],\n",
      "        [70, 70, 77,  1, 33,  1, 75, 53],\n",
      "        [71,  1, 53,  1, 75, 67, 65, 53],\n",
      "        [61, 64, 64,  1, 54, 57,  1, 71],\n",
      "        [ 9,  1, 40, 67, 56,  7,  1, 70]])\n",
      "-------------------------\n",
      "Input : tensor([54]) -> Target : 53\n",
      "Input : tensor([54, 53]) -> Target : 70\n",
      "Input : tensor([54, 53, 70]) -> Target : 53\n",
      "Input : tensor([54, 53, 70, 53]) -> Target : 72\n",
      "Input : tensor([54, 53, 70, 53, 72]) -> Target : 60\n",
      "Input : tensor([54, 53, 70, 53, 72, 60]) -> Target : 57\n",
      "Input : tensor([54, 53, 70, 53, 72, 60, 57]) -> Target : 67\n",
      "Input : tensor([54, 53, 70, 53, 72, 60, 57, 67]) -> Target : 66\n",
      "Input : tensor([60]) -> Target : 57\n",
      "Input : tensor([60, 57]) -> Target : 77\n",
      "Input : tensor([60, 57, 77]) -> Target : 5\n",
      "Input : tensor([60, 57, 77,  5]) -> Target : 64\n",
      "Input : tensor([60, 57, 77,  5, 64]) -> Target : 64\n",
      "Input : tensor([60, 57, 77,  5, 64, 64]) -> Target : 1\n",
      "Input : tensor([60, 57, 77,  5, 64, 64,  1]) -> Target : 63\n",
      "Input : tensor([60, 57, 77,  5, 64, 64,  1, 63]) -> Target : 61\n",
      "Input : tensor([72]) -> Target : 60\n",
      "Input : tensor([72, 60]) -> Target : 1\n",
      "Input : tensor([72, 60,  1]) -> Target : 72\n",
      "Input : tensor([72, 60,  1, 72]) -> Target : 60\n",
      "Input : tensor([72, 60,  1, 72, 60]) -> Target : 57\n",
      "Input : tensor([72, 60,  1, 72, 60, 57]) -> Target : 1\n",
      "Input : tensor([72, 60,  1, 72, 60, 57,  1]) -> Target : 75\n",
      "Input : tensor([72, 60,  1, 72, 60, 57,  1, 75]) -> Target : 60\n",
      "Input : tensor([63]) -> Target : 71\n",
      "Input : tensor([63, 71]) -> Target : 1\n",
      "Input : tensor([63, 71,  1]) -> Target : 57\n",
      "Input : tensor([63, 71,  1, 57]) -> Target : 74\n",
      "Input : tensor([63, 71,  1, 57, 74]) -> Target : 57\n",
      "Input : tensor([63, 71,  1, 57, 74, 57]) -> Target : 70\n",
      "Input : tensor([63, 71,  1, 57, 74, 57, 70]) -> Target : 77\n",
      "Input : tensor([63, 71,  1, 57, 74, 57, 70, 77]) -> Target : 1\n",
      "Input : tensor([67]) -> Target : 70\n",
      "Input : tensor([67, 70]) -> Target : 70\n",
      "Input : tensor([67, 70, 70]) -> Target : 77\n",
      "Input : tensor([67, 70, 70, 77]) -> Target : 1\n",
      "Input : tensor([67, 70, 70, 77,  1]) -> Target : 33\n",
      "Input : tensor([67, 70, 70, 77,  1, 33]) -> Target : 1\n",
      "Input : tensor([67, 70, 70, 77,  1, 33,  1]) -> Target : 75\n",
      "Input : tensor([67, 70, 70, 77,  1, 33,  1, 75]) -> Target : 53\n",
      "Input : tensor([53]) -> Target : 71\n",
      "Input : tensor([53, 71]) -> Target : 1\n",
      "Input : tensor([53, 71,  1]) -> Target : 53\n",
      "Input : tensor([53, 71,  1, 53]) -> Target : 1\n",
      "Input : tensor([53, 71,  1, 53,  1]) -> Target : 75\n",
      "Input : tensor([53, 71,  1, 53,  1, 75]) -> Target : 67\n",
      "Input : tensor([53, 71,  1, 53,  1, 75, 67]) -> Target : 65\n",
      "Input : tensor([53, 71,  1, 53,  1, 75, 67, 65]) -> Target : 53\n",
      "Input : tensor([75]) -> Target : 61\n",
      "Input : tensor([75, 61]) -> Target : 64\n",
      "Input : tensor([75, 61, 64]) -> Target : 64\n",
      "Input : tensor([75, 61, 64, 64]) -> Target : 1\n",
      "Input : tensor([75, 61, 64, 64,  1]) -> Target : 54\n",
      "Input : tensor([75, 61, 64, 64,  1, 54]) -> Target : 57\n",
      "Input : tensor([75, 61, 64, 64,  1, 54, 57]) -> Target : 1\n",
      "Input : tensor([75, 61, 64, 64,  1, 54, 57,  1]) -> Target : 71\n",
      "Input : tensor([56]) -> Target : 9\n",
      "Input : tensor([56,  9]) -> Target : 1\n",
      "Input : tensor([56,  9,  1]) -> Target : 40\n",
      "Input : tensor([56,  9,  1, 40]) -> Target : 67\n",
      "Input : tensor([56,  9,  1, 40, 67]) -> Target : 56\n",
      "Input : tensor([56,  9,  1, 40, 67, 56]) -> Target : 7\n",
      "Input : tensor([56,  9,  1, 40, 67, 56,  7]) -> Target : 1\n",
      "Input : tensor([56,  9,  1, 40, 67, 56,  7,  1]) -> Target : 70\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1709)\n",
    "batchSize = 8\n",
    "blockSize = 8\n",
    "\n",
    "def getBatch(splitType):\n",
    "\n",
    "    data = trainTensor if splitType==\"train\" else validTensor\n",
    "    ix = torch.randint(len(trainTensor)-blockSize, (batchSize,))\n",
    "    # print(ix)\n",
    "    x = torch.stack([data[i:i+blockSize] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+blockSize+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xBatch, yBatch = getBatch('train')\n",
    "print('inputs :')\n",
    "print(xBatch)\n",
    "print('targets:')\n",
    "print(yBatch)\n",
    "\n",
    "\n",
    "print(\"-\" * 25)\n",
    "for b in range(batchSize):\n",
    "    for t in range(blockSize):\n",
    "        context = xBatch[b, :t+1]\n",
    "        target = yBatch[b,t]\n",
    "        print(f\"Input : {context} -> Target : {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1709)\n",
    "\n",
    "class BigramLM(nn.Module):\n",
    "    def __init__(self, vocabSize):\n",
    "        super(BigramLM, self).__init__()\n",
    "        self.tokenEmbeddings = nn.Embedding(vocabSize, vocabSize)  # (batch, time, channel)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.tokenEmbeddings(idx)  # (batch, time, channel)\n",
    "\n",
    "        if targets is not None:\n",
    "            batch, time, channel = logits.shape\n",
    "            logits = logits.view(batch * time, channel)  # Flatten for cross-entropy\n",
    "            targets = targets.view(-1)  # Flatten targets\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss  # Ensure logits are always returned\n",
    "\n",
    "    def generate(self, idx, maxNewTokens):\n",
    "        \"\"\"Generate new tokens based on input idx\"\"\"\n",
    "        for _ in range(maxNewTokens):\n",
    "            logits, _ = self(idx)  # Get predictions\n",
    "            logits = logits[:, -1, :]  # Take last token's logits\n",
    "            probs = F.softmax(logits, dim=-1)  # Apply softmax\n",
    "            idxNext = torch.multinomial(probs, num_samples=1)  # Sample from probs\n",
    "            idx = torch.cat((idx, idxNext), dim=1)  # Append new token\n",
    "        return idx\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 91])\n",
      "tensor(4.8613, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = BigramLM(vocabSize)\n",
    "logits, loss = model(xBatch, yBatch)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XTD.b6,98“#buSDhOyYQJb]sw\n",
      "tg7q2]Qz2mMvru3YNOAkZUAa0Bj0ē[sd:—>*TizvCajiJ0uGpSDt -kiW\n",
      "E5\"KxqTSwg.]rr\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(model.generate(idx, maxNewTokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.297551393508911\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "batchSize = 32\n",
    "\n",
    "for steps in range(10000):\n",
    "\n",
    "    xBatch, yBatch = getBatch('train')\n",
    "\n",
    "    logits, loss = model(xBatch, yBatch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IEt Don .\n",
      "t is f wanddwin in.\n",
      "can goursse pe the mathon w cco ar woue. i:\n",
      "Mygty {nsthacong I'smeenoum m ntheke u e tis I ondan bas aLaf ga]0ay'tl brs tte Itf rind itlis f m oulitlve imance s t Yemonlenod yong, ke]zhowar:\n",
      "\n",
      "\n",
      "Thare ms fr:\n",
      "\n",
      "\n",
      "Holk t ane Ne.\n",
      "t I ll oure. Al.\n",
      "I2yons qutheore. ans?\n",
      "… wa les grsthrk ansen an't'rovericou s, l. win h me.\n",
      "Wh, t ther co'st inorshenll.\n",
      "\n",
      "Therowathanst We'sa g'sa cl Labade, f Da aist?\n",
      "\n",
      "mba lat wheawinin fae gae drat.\n",
      "jethaifisal wēSoomo:\n",
      "Doure y, my bate seses Wand hinitysn h:\n",
      "ctoxer, prerthe.\n",
      "\n",
      "\n",
      "Se.\n",
      "veys Yofitts\n",
      "\n",
      "s m st:\n",
      "\n",
      "18HL*lad gee hensoner:\n",
      "Thabaystheapper:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Whesavald de n be wim aist arld ldome:\n",
      "Spprinnorcalwit thex4āz–8PéHon Foucae. ms Astrgineroban“>Yonear, s D:\n",
      "\n",
      "{Kioway:\n",
      "p mayenor uisangivindg, Dowousot k.\n",
      "tisen--\n",
      "M\"reay Cojoum.\n",
      "An sererin joucaery mlth vevecaling, Fit. hedrcl innttie obof d ongamem?\n",
      "\n",
      "I ted l S\". t clliouRouronn hou'smer f.\n",
      "stit barebetede Sburereim pe the weeisaghen Kingheasted t wofie w Ju. yopend wone lureren':\n",
      "\n",
      "thener.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(idx, maxNewTokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math - Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5306, -1.1300],\n",
      "         [-0.6734, -0.7669],\n",
      "         [-0.7029,  0.9896],\n",
      "         [-0.4482,  0.8927],\n",
      "         [ 0.6976, -0.7904],\n",
      "         [ 0.8441,  0.0935],\n",
      "         [ 0.3769,  0.9941],\n",
      "         [-0.9810,  0.3350]],\n",
      "\n",
      "        [[-1.1749, -0.2915],\n",
      "         [-0.6320, -0.2054],\n",
      "         [-0.0921, -0.7026],\n",
      "         [ 0.1493,  0.0623],\n",
      "         [ 0.9540,  0.1091],\n",
      "         [-0.9644,  0.1029],\n",
      "         [ 0.1336, -1.5383],\n",
      "         [-0.3572,  0.4610]],\n",
      "\n",
      "        [[-1.2604,  2.7814],\n",
      "         [-1.6488,  3.1110],\n",
      "         [ 0.9132, -0.9749],\n",
      "         [ 0.7901,  1.3059],\n",
      "         [ 0.7001,  0.0592],\n",
      "         [ 1.2133, -0.4085],\n",
      "         [-0.3143, -0.9397],\n",
      "         [-0.4881,  0.2953]],\n",
      "\n",
      "        [[ 1.4242, -0.5333],\n",
      "         [ 1.6785,  1.2637],\n",
      "         [-1.8353, -0.5558],\n",
      "         [-0.7608,  0.5794],\n",
      "         [ 0.1332, -0.8094],\n",
      "         [-2.4259, -1.2058],\n",
      "         [-1.0667,  1.5432],\n",
      "         [ 0.1225,  0.0838]]])\n",
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "#sample eg\n",
    "\n",
    "torch.manual_seed(1000)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B,T,C)\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1\n",
    "# #x[b,t] = mean_{i <= t} x[b,i]\n",
    "xbow = torch.zeros(B,T,C)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xPrev = x[b,:t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xPrev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5306, -1.1300],\n",
       "         [-0.6020, -0.9484],\n",
       "         [-0.6356, -0.3024],\n",
       "         [-0.5888, -0.0036],\n",
       "         [-0.3315, -0.1610],\n",
       "         [-0.1355, -0.1186],\n",
       "         [-0.0623,  0.0404],\n",
       "         [-0.1772,  0.0772]],\n",
       "\n",
       "        [[-1.1749, -0.2915],\n",
       "         [-0.9035, -0.2484],\n",
       "         [-0.6330, -0.3998],\n",
       "         [-0.4374, -0.2843],\n",
       "         [-0.1592, -0.2056],\n",
       "         [-0.2934, -0.1542],\n",
       "         [-0.2324, -0.3519],\n",
       "         [-0.2480, -0.2503]],\n",
       "\n",
       "        [[-1.2604,  2.7814],\n",
       "         [-1.4546,  2.9462],\n",
       "         [-0.6653,  1.6392],\n",
       "         [-0.3015,  1.5559],\n",
       "         [-0.1012,  1.2565],\n",
       "         [ 0.1179,  0.9790],\n",
       "         [ 0.0562,  0.7049],\n",
       "         [-0.0119,  0.6537]],\n",
       "\n",
       "        [[ 1.4242, -0.5333],\n",
       "         [ 1.5514,  0.3652],\n",
       "         [ 0.4225,  0.0582],\n",
       "         [ 0.1267,  0.1885],\n",
       "         [ 0.1280, -0.0111],\n",
       "         [-0.2977, -0.2102],\n",
       "         [-0.4075,  0.0403],\n",
       "         [-0.3413,  0.0457]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "tensor([[[-0.5306, -1.1300],\n",
      "         [-0.6020, -0.9484],\n",
      "         [-0.6356, -0.3024],\n",
      "         [-0.5888, -0.0036],\n",
      "         [-0.3315, -0.1610],\n",
      "         [-0.1355, -0.1186],\n",
      "         [-0.0623,  0.0404],\n",
      "         [-0.1772,  0.0772]],\n",
      "\n",
      "        [[-1.1749, -0.2915],\n",
      "         [-0.9035, -0.2484],\n",
      "         [-0.6330, -0.3998],\n",
      "         [-0.4374, -0.2843],\n",
      "         [-0.1592, -0.2056],\n",
      "         [-0.2934, -0.1542],\n",
      "         [-0.2324, -0.3519],\n",
      "         [-0.2480, -0.2503]],\n",
      "\n",
      "        [[-1.2604,  2.7814],\n",
      "         [-1.4546,  2.9462],\n",
      "         [-0.6653,  1.6392],\n",
      "         [-0.3015,  1.5559],\n",
      "         [-0.1012,  1.2565],\n",
      "         [ 0.1179,  0.9790],\n",
      "         [ 0.0562,  0.7049],\n",
      "         [-0.0119,  0.6537]],\n",
      "\n",
      "        [[ 1.4242, -0.5333],\n",
      "         [ 1.5514,  0.3652],\n",
      "         [ 0.4225,  0.0582],\n",
      "         [ 0.1267,  0.1885],\n",
      "         [ 0.1280, -0.0111],\n",
      "         [-0.2977, -0.2102],\n",
      "         [-0.4075,  0.0403],\n",
      "         [-0.3413,  0.0457]]])\n"
     ]
    }
   ],
   "source": [
    "#version 2\n",
    "weights = torch.tril(torch.ones(T,T))\n",
    "weights = weights /weights.sum(1, keepdim=True)\n",
    "print(weights)\n",
    "\n",
    "xbow2 = weights @ x # (T,T) becomes (B, T, T) @ (B, T, C) -> (B, T, C) (* batch wise multiplication)\n",
    "\n",
    "print(xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.zeros(T,T)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "tensor([[[-0.5306, -1.1300],\n",
      "         [-0.6020, -0.9484],\n",
      "         [-0.6356, -0.3024],\n",
      "         [-0.5888, -0.0036],\n",
      "         [-0.3315, -0.1610],\n",
      "         [-0.1355, -0.1186],\n",
      "         [-0.0623,  0.0404],\n",
      "         [-0.1772,  0.0772]],\n",
      "\n",
      "        [[-1.1749, -0.2915],\n",
      "         [-0.9035, -0.2484],\n",
      "         [-0.6330, -0.3998],\n",
      "         [-0.4374, -0.2843],\n",
      "         [-0.1592, -0.2056],\n",
      "         [-0.2934, -0.1542],\n",
      "         [-0.2324, -0.3519],\n",
      "         [-0.2480, -0.2503]],\n",
      "\n",
      "        [[-1.2604,  2.7814],\n",
      "         [-1.4546,  2.9462],\n",
      "         [-0.6653,  1.6392],\n",
      "         [-0.3015,  1.5559],\n",
      "         [-0.1012,  1.2565],\n",
      "         [ 0.1179,  0.9790],\n",
      "         [ 0.0562,  0.7049],\n",
      "         [-0.0119,  0.6537]],\n",
      "\n",
      "        [[ 1.4242, -0.5333],\n",
      "         [ 1.5514,  0.3652],\n",
      "         [ 0.4225,  0.0582],\n",
      "         [ 0.1267,  0.1885],\n",
      "         [ 0.1280, -0.0111],\n",
      "         [-0.2977, -0.2102],\n",
      "         [-0.4075,  0.0403],\n",
      "         [-0.3413,  0.0457]]])\n"
     ]
    }
   ],
   "source": [
    "#version 3\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "print(weights)\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "print(weights)\n",
    "xbow3 = weights @ x\n",
    "print(xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 4\n",
    "\n",
    "torch.manual_seed(1000)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "\n",
    "#single head self-attention\n",
    "headDim = 16\n",
    "\n",
    "query = nn.Linear(C, headDim, bias=False)# what am I looking for\n",
    "key = nn.Linear(C, headDim, bias=False)# what do i contain\n",
    "value = nn.Linear(C, headDim, bias=False)\n",
    "\n",
    "k = key(x) # (B, T, headDim)\n",
    "q = query(x) # (B, T, headDim)\n",
    "v = value(x)\n",
    "\n",
    "weights = q @ k.transpose(-2, -1) # (B, T, headDim) * (B, headDim, T) -> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "# weights = torch.zeros((T,T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "# print(weights)\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "output = weights @ v\n",
    "\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7688, 0.2312, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1641, 0.7803, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8749, 0.1055, 0.0122, 0.0073, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1247, 0.0082, 0.2009, 0.1139, 0.5522, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2528, 0.0298, 0.1988, 0.4034, 0.0975, 0.0176, 0.0000, 0.0000],\n",
       "        [0.3124, 0.1451, 0.0352, 0.0081, 0.3890, 0.0757, 0.0344, 0.0000],\n",
       "        [0.0173, 0.7327, 0.0540, 0.0117, 0.0034, 0.0274, 0.0505, 0.1028]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In encoder, we have to consider all the tokens to compute the attention weights, whereas in decoder we have to consider only the present and past tokens and mask all the future tokens using mask fill.\n",
    "* In self attention, it captures relationships within the same sequence(source), while cross-attention connects tokens from different sequences, such as in encoder-decoder interactions.\n",
    "* For scaled attention, we divide QK^T by sqrt(headDim) to keep the variance stable and prevent extremely large values, ensuring that the softmax function produces well-balanced attention weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wothmag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
